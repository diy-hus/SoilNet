{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed2af90-41fe-421f-9437-c88c92c6a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6074e36-5ec1-418c-a3ed-7418a23fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Kiểm tra và đặt thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd6067-3711-4638-95c3-5a4091e0e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df):\n",
    "    new_df = df.copy()\n",
    "    deleted_count = 0\n",
    "    valid_indices = []\n",
    "    for idx, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "        path = row[\"path\"]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            valid_indices.append(idx)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    new_df = new_df.loc[valid_indices].reset_index(drop=True)\n",
    "    logging.info(f\"Deleted {deleted_count} labeled images. {len(new_df)} images remain.\")\n",
    "    return new_df\n",
    "\n",
    "def preprocess_unlabeled_images(image_paths):\n",
    "    new_image_paths = []\n",
    "    deleted_count = 0\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            new_image_paths.append(path)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    logging.info(f\"Deleted {deleted_count} unlabeled images. {len(new_image_paths)} images remain.\")\n",
    "    return new_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190a3635-2aaa-4852-8846-996eb51d127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2057/2057 [01:26<00:00, 23.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2052/2052 [01:08<00:00, 30.09it/s]\n"
     ]
    }
   ],
   "source": [
    "label_csv_path = r\"F:\\Soil_Labeled_Data\\labels.csv\"\n",
    "fallback_dir = r\"F:\\Soil_Labeled_Data\\augmented_fallback\"\n",
    "os.makedirs(fallback_dir, exist_ok=True)\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df = preprocess_images(df)\n",
    "\n",
    "augment = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "replaced_count = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    path = row[\"path\"]\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img.verify()\n",
    "    except (UnidentifiedImageError, FileNotFoundError, OSError):\n",
    "        folder = os.path.dirname(path)\n",
    "        all_images = [f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "        good_images = [f for f in all_images if f != os.path.basename(path)]\n",
    "        if not good_images:\n",
    "            continue\n",
    "        candidate = random.choice(good_images)\n",
    "        candidate_path = os.path.join(folder, candidate)\n",
    "        try:\n",
    "            img = Image.open(candidate_path).convert(\"RGB\")\n",
    "            img_aug = augment(img)\n",
    "            new_filename = f\"aug_{os.path.basename(path)}\"\n",
    "            new_path = os.path.join(fallback_dir, new_filename)\n",
    "            img_aug.save(new_path)\n",
    "            df.at[idx, \"path\"] = new_path\n",
    "            replaced_count += 1\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba635eb-f1dc-4fbd-a0d8-0227a00e0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11995/11995 [02:31<00:00, 79.20it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dir = r\"F:/unlabeled_images\"\n",
    "image_paths = []\n",
    "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"]:\n",
    "    image_paths.extend(glob.glob(os.path.join(image_dir, \"**\", ext), recursive=True))\n",
    "image_paths = preprocess_unlabeled_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96588c62-959b-4472-be0f-fbcc5eb1f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "labeled_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img1 = self.transform(image)\n",
    "            img2 = self.transform(image)\n",
    "            return img1, img2\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_paths))\n",
    "\n",
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(image)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        humidity = torch.tensor([row['SM_0'] / 100, row['SM_20'] / 100], dtype=torch.float32)\n",
    "        class_label = torch.tensor(row[\"moisture_class\"], dtype=torch.long)\n",
    "        return img, humidity, class_label\n",
    "\n",
    "unlabeled_dataset = UnlabeledImageDataset(image_paths, transform)\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "labeled_dataset = LabeledImageDataset(df, labeled_transform)\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "class SoilNetDualHead(nn.Module):\n",
    "    def __init__(self, num_classes=10, simclr_mode=False):\n",
    "        super().__init__()\n",
    "        self.simclr_mode = simclr_mode\n",
    "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.mnv2_block1 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[0:3]\n",
    "        )\n",
    "        self.channel_adapter = nn.Conv2d(32, 16, kernel_size=1, bias=False)\n",
    "        self.mobilevit_full = timm.create_model(\"mobilevitv2_050\", pretrained=True)\n",
    "        self.mobilevit_encoder = self.mobilevit_full.stages\n",
    "        self.mvit_to_mnv2 = nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "        self.mnv2_block2 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[3:7]\n",
    "        )\n",
    "        self.final_conv = nn.Conv2d(320, 1280, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.light_dense = nn.Sequential(nn.Linear(1, 32), nn.ReLU(inplace=True))\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_light=None):\n",
    "        x = self.initial_conv(x_img)\n",
    "        x = self.mnv2_block1(x)\n",
    "        x = self.channel_adapter(x)\n",
    "        x = self.mobilevit_encoder(x)\n",
    "        x = self.mvit_to_mnv2(x)\n",
    "        x = self.mnv2_block2(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.pool(x)\n",
    "        x_img_feat = torch.flatten(x, 1)\n",
    "        if self.simclr_mode:\n",
    "            return x_img_feat\n",
    "        x_light_feat = self.light_dense(x_light)\n",
    "        x_concat = torch.cat([x_img_feat, x_light_feat], dim=1)\n",
    "        reg_out = self.reg_head(x_concat)\n",
    "        cls_out = self.cls_head(x_concat)\n",
    "        return reg_out, cls_out\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, input_dim=1280, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class OnlineLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class OnlineClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def vicreg_loss(z1, z2, lambda_=25.0, mu=25.0, nu=1.0, epsilon=1e-4):\n",
    "    invariance_loss = F.mse_loss(z1, z2)\n",
    "    def variance_term(z):\n",
    "        z_std = torch.sqrt(z.var(dim=0) + epsilon)\n",
    "        return torch.mean(F.relu(1 - z_std))\n",
    "    var_loss = variance_term(z1) + variance_term(z2)\n",
    "    def covariance_term(z):\n",
    "        z = z - z.mean(dim=0)\n",
    "        cov = (z.T @ z) / (z.shape[0] - 1)\n",
    "        off_diag = cov - torch.diag(cov.diag())\n",
    "        return off_diag.pow(2).sum() / z.shape[1]\n",
    "    cov_loss = covariance_term(z1) + covariance_term(z2)\n",
    "    return lambda_ * invariance_loss + mu * var_loss + nu * cov_loss\n",
    "\n",
    "model = SoilNetDualHead(num_classes=10, simclr_mode=True).to(device)\n",
    "projector = Projector(input_dim=1280, proj_dim=128).to(device)\n",
    "linear_reg = OnlineLinearRegression(input_dim=1280, output_dim=2).to(device)\n",
    "classifier = OnlineClassifier(input_dim=1280, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89271f6e-e617-4fb5-84bf-ee8d8d7132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(r\"C:\\Users\\PC\\soilNet\\Model\\SoilNet_orginal.pth\", map_location=device))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "optimizer_vicreg = torch.optim.Adam(list(model.parameters()) + list(projector.parameters()), lr=1e-4)\n",
    "optimizer_linear = torch.optim.Adam(linear_reg.parameters(), lr=1e-3)\n",
    "optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "#checkpoint_dir = \"/content/drive/MyDrive/SoilNet_Checkpoints/checkpoints_VicReg\"\n",
    "checkpoint_dir = r\"C:\\Users\\PC\\soilNet\\checkpoints_VicReg\"\n",
    "\n",
    "#C:\\Users\\PC\\soilNet\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e040f89a-3f5e-47ed-ad72-c2edf6eff441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   1/60 (mu=40.0) - VICReg Loss: 48.9605, MSE: 1732.8682, RMSE: 41.6277, MAE: 32.0730, Accuracy: 0.17289720, F1-Score: 0.17195368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   2/60 (mu=40.0) - VICReg Loss: 46.2619, MSE: 1112.3062, RMSE: 33.3513, MAE: 26.5857, Accuracy: 0.18733311, F1-Score: 0.18924459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   3/60 (mu=40.0) - VICReg Loss: 43.6585, MSE: 969.9264, RMSE: 31.1436, MAE: 24.9095, Accuracy: 0.20201936, F1-Score: 0.20525138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   4/60 (mu=40.0) - VICReg Loss: 41.5887, MSE: 904.8640, RMSE: 30.0810, MAE: 23.9573, Accuracy: 0.20752670, F1-Score: 0.21216960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   5/60 (mu=40.0) - VICReg Loss: 39.3744, MSE: 826.3259, RMSE: 28.7459, MAE: 22.9081, Accuracy: 0.21987650, F1-Score: 0.22562325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   6/60 (mu=40.0) - VICReg Loss: 37.5291, MSE: 823.0005, RMSE: 28.6880, MAE: 22.7572, Accuracy: 0.23205941, F1-Score: 0.23742073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   7/60 (mu=40.0) - VICReg Loss: 35.4541, MSE: 781.5115, RMSE: 27.9555, MAE: 22.2432, Accuracy: 0.24040387, F1-Score: 0.24334954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   8/60 (mu=40.0) - VICReg Loss: 33.3897, MSE: 762.7651, RMSE: 27.6182, MAE: 21.7932, Accuracy: 0.24958278, F1-Score: 0.25321785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   9/60 (mu=40.0) - VICReg Loss: 31.9110, MSE: 741.7087, RMSE: 27.2343, MAE: 21.5855, Accuracy: 0.24482644, F1-Score: 0.24894860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  10/60 (mu=40.0) - VICReg Loss: 30.1907, MSE: 719.8226, RMSE: 26.8295, MAE: 21.3061, Accuracy: 0.24682911, F1-Score: 0.25003629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  11/60 (mu=40.0) - VICReg Loss: 28.9171, MSE: 723.7554, RMSE: 26.9027, MAE: 21.2964, Accuracy: 0.26285047, F1-Score: 0.26835028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  12/60 (mu=40.0) - VICReg Loss: 27.8374, MSE: 721.9499, RMSE: 26.8691, MAE: 21.2312, Accuracy: 0.25959613, F1-Score: 0.26351854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  13/60 (mu=40.0) - VICReg Loss: 26.6222, MSE: 745.7275, RMSE: 27.3080, MAE: 21.6992, Accuracy: 0.25458945, F1-Score: 0.25990249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  14/60 (mu=40.0) - VICReg Loss: 25.6502, MSE: 705.8641, RMSE: 26.5681, MAE: 21.0788, Accuracy: 0.26068091, F1-Score: 0.26731747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  15/60 (mu=40.0) - VICReg Loss: 25.0148, MSE: 687.6957, RMSE: 26.2240, MAE: 20.7953, Accuracy: 0.26693925, F1-Score: 0.27251480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  16/60 (mu=40.0) - VICReg Loss: 24.5067, MSE: 723.6676, RMSE: 26.9011, MAE: 21.3594, Accuracy: 0.25600801, F1-Score: 0.25887407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  17/60 (mu=40.0) - VICReg Loss: 24.0326, MSE: 710.1038, RMSE: 26.6478, MAE: 21.1201, Accuracy: 0.26243324, F1-Score: 0.26799880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  18/60 (mu=40.0) - VICReg Loss: 23.5000, MSE: 732.2558, RMSE: 27.0602, MAE: 21.5515, Accuracy: 0.26018024, F1-Score: 0.26578140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  19/60 (mu=40.0) - VICReg Loss: 23.0716, MSE: 746.3037, RMSE: 27.3186, MAE: 21.7503, Accuracy: 0.25425567, F1-Score: 0.25992116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  20/60 (mu=40.0) - VICReg Loss: 22.8554, MSE: 764.4359, RMSE: 27.6484, MAE: 22.0576, Accuracy: 0.25083445, F1-Score: 0.25570722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  21/60 (mu=40.0) - VICReg Loss: 22.4227, MSE: 727.3363, RMSE: 26.9692, MAE: 21.5583, Accuracy: 0.25967957, F1-Score: 0.26460926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  22/60 (mu=40.0) - VICReg Loss: 22.1596, MSE: 727.1308, RMSE: 26.9654, MAE: 21.5865, Accuracy: 0.25642523, F1-Score: 0.26066951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  23/60 (mu=40.0) - VICReg Loss: 21.9705, MSE: 771.0009, RMSE: 27.7669, MAE: 22.0340, Accuracy: 0.24849800, F1-Score: 0.25364676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  24/60 (mu=40.0) - VICReg Loss: 21.8223, MSE: 779.8635, RMSE: 27.9260, MAE: 22.3772, Accuracy: 0.24833111, F1-Score: 0.25224373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  25/60 (mu=40.0) - VICReg Loss: 21.6128, MSE: 775.3808, RMSE: 27.8457, MAE: 22.3226, Accuracy: 0.24908211, F1-Score: 0.25313539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  26/60 (mu=40.0) - VICReg Loss: 21.4523, MSE: 802.7006, RMSE: 28.3320, MAE: 22.6584, Accuracy: 0.24741322, F1-Score: 0.25169823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  27/60 (mu=40.0) - VICReg Loss: 21.2743, MSE: 811.3206, RMSE: 28.4837, MAE: 22.8324, Accuracy: 0.24599466, F1-Score: 0.25084458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  28/60 (mu=40.0) - VICReg Loss: 21.2526, MSE: 818.7957, RMSE: 28.6146, MAE: 22.8413, Accuracy: 0.24365821, F1-Score: 0.24934529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  29/60 (mu=40.0) - VICReg Loss: 21.1697, MSE: 765.0023, RMSE: 27.6587, MAE: 22.2157, Accuracy: 0.24057076, F1-Score: 0.24476440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  30/60 (mu=40.0) - VICReg Loss: 20.8926, MSE: 788.7064, RMSE: 28.0839, MAE: 22.6174, Accuracy: 0.25325434, F1-Score: 0.25691782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  31/60 (mu=40.0) - VICReg Loss: 20.7276, MSE: 832.0699, RMSE: 28.8456, MAE: 23.1029, Accuracy: 0.24349132, F1-Score: 0.24699103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  32/60 (mu=40.0) - VICReg Loss: 20.8878, MSE: 794.5934, RMSE: 28.1885, MAE: 22.5838, Accuracy: 0.24974967, F1-Score: 0.25296202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  33/60 (mu=40.0) - VICReg Loss: 20.5918, MSE: 816.0444, RMSE: 28.5665, MAE: 22.8864, Accuracy: 0.24390854, F1-Score: 0.24834879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  34/60 (mu=40.0) - VICReg Loss: 20.5806, MSE: 820.0492, RMSE: 28.6365, MAE: 22.9194, Accuracy: 0.24165554, F1-Score: 0.24816534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  35/60 (mu=40.0) - VICReg Loss: 20.4547, MSE: 825.5019, RMSE: 28.7315, MAE: 23.1176, Accuracy: 0.24057076, F1-Score: 0.24446667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  36/60 (mu=40.0) - VICReg Loss: 20.4189, MSE: 825.3358, RMSE: 28.7287, MAE: 23.1324, Accuracy: 0.24057076, F1-Score: 0.24425655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  37/60 (mu=40.0) - VICReg Loss: 20.2531, MSE: 848.2599, RMSE: 29.1249, MAE: 23.3109, Accuracy: 0.23247664, F1-Score: 0.23646933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  38/60 (mu=40.0) - VICReg Loss: 20.4110, MSE: 818.9186, RMSE: 28.6168, MAE: 22.9766, Accuracy: 0.23756676, F1-Score: 0.24121024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  39/60 (mu=40.0) - VICReg Loss: 20.1752, MSE: 825.7832, RMSE: 28.7364, MAE: 23.1203, Accuracy: 0.23598131, F1-Score: 0.23979042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  40/60 (mu=40.0) - VICReg Loss: 20.1521, MSE: 859.3366, RMSE: 29.3144, MAE: 23.5525, Accuracy: 0.23898531, F1-Score: 0.24289383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  41/60 (mu=40.0) - VICReg Loss: 20.0496, MSE: 860.3207, RMSE: 29.3312, MAE: 23.5230, Accuracy: 0.24065421, F1-Score: 0.24322304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  42/60 (mu=40.0) - VICReg Loss: 19.9995, MSE: 865.3335, RMSE: 29.4166, MAE: 23.6521, Accuracy: 0.23039052, F1-Score: 0.23295902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  43/60 (mu=40.0) - VICReg Loss: 19.9586, MSE: 877.1111, RMSE: 29.6161, MAE: 23.8224, Accuracy: 0.23189252, F1-Score: 0.23242120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  44/60 (mu=40.0) - VICReg Loss: 19.8202, MSE: 872.8904, RMSE: 29.5447, MAE: 23.8357, Accuracy: 0.22204606, F1-Score: 0.22395167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  45/60 (mu=40.0) - VICReg Loss: 19.8947, MSE: 881.2691, RMSE: 29.6862, MAE: 23.9548, Accuracy: 0.22913885, F1-Score: 0.23129543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  46/60 (mu=40.0) - VICReg Loss: 19.8806, MSE: 844.3941, RMSE: 29.0585, MAE: 23.3409, Accuracy: 0.23205941, F1-Score: 0.23433427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  47/60 (mu=40.0) - VICReg Loss: 19.8519, MSE: 843.8860, RMSE: 29.0497, MAE: 23.2992, Accuracy: 0.23055741, F1-Score: 0.23271412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  48/60 (mu=40.0) - VICReg Loss: 19.6433, MSE: 886.1835, RMSE: 29.7688, MAE: 24.1080, Accuracy: 0.22963952, F1-Score: 0.23081966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  49/60 (mu=40.0) - VICReg Loss: 19.8065, MSE: 870.7915, RMSE: 29.5092, MAE: 23.7753, Accuracy: 0.22963952, F1-Score: 0.23153020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  50/60 (mu=40.0) - VICReg Loss: 19.7028, MSE: 871.3399, RMSE: 29.5185, MAE: 23.7199, Accuracy: 0.22897196, F1-Score: 0.22973609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  51/60 (mu=40.0) - VICReg Loss: 19.7041, MSE: 851.2474, RMSE: 29.1761, MAE: 23.5816, Accuracy: 0.22980641, F1-Score: 0.23375144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  52/60 (mu=40.0) - VICReg Loss: 19.6478, MSE: 841.2927, RMSE: 29.0050, MAE: 23.5539, Accuracy: 0.23681575, F1-Score: 0.23821096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  53/60 (mu=40.0) - VICReg Loss: 19.4485, MSE: 853.2415, RMSE: 29.2103, MAE: 23.5801, Accuracy: 0.23230975, F1-Score: 0.23438451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  54/60 (mu=40.0) - VICReg Loss: 19.6178, MSE: 881.6851, RMSE: 29.6932, MAE: 23.9545, Accuracy: 0.22571762, F1-Score: 0.22446344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  55/60 (mu=40.0) - VICReg Loss: 19.4987, MSE: 891.7460, RMSE: 29.8621, MAE: 24.1785, Accuracy: 0.22596796, F1-Score: 0.22708844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  56/60 (mu=40.0) - VICReg Loss: 19.4618, MSE: 875.3170, RMSE: 29.5858, MAE: 23.9309, Accuracy: 0.22062750, F1-Score: 0.22363867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  57/60 (mu=40.0) - VICReg Loss: 19.4251, MSE: 823.0781, RMSE: 28.6893, MAE: 23.1865, Accuracy: 0.23406208, F1-Score: 0.23418288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  58/60 (mu=40.0) - VICReg Loss: 19.3713, MSE: 873.2857, RMSE: 29.5514, MAE: 23.9605, Accuracy: 0.22838785, F1-Score: 0.23039542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  59/60 (mu=40.0) - VICReg Loss: 19.3424, MSE: 902.2045, RMSE: 30.0367, MAE: 24.2495, Accuracy: 0.22146195, F1-Score: 0.22205152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  60/60 (mu=40.0) - VICReg Loss: 19.2750, MSE: 893.1642, RMSE: 29.8859, MAE: 24.1098, Accuracy: 0.22321429, F1-Score: 0.22610816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def train_vicreg_with_mu(mu=25.0, num_epochs=150, metrics_df=None):\n",
    "    vicreg_losses, mse_losses, rmse_losses, mae_losses, accuracy_scores, f1_scores = [], [], [], [], [], []\n",
    "    labeled_iterator = iter(labeled_dataloader)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        projector.train()\n",
    "        linear_reg.train()\n",
    "        classifier.train()\n",
    "        running_vicreg_loss = running_mse = running_mae = running_accuracy = running_f1 = 0.0\n",
    "        num_batches = 0\n",
    "        for img1, img2 in tqdm(unlabeled_dataloader, leave=False):\n",
    "            img1, img2 = img1.to(device), img2.to(device)\n",
    "            feat1 = model(img1, x_light=None)\n",
    "            feat2 = model(img2, x_light=None)\n",
    "            z1 = projector(feat1)\n",
    "            z2 = projector(feat2)\n",
    "            vicreg_loss_val = vicreg_loss(z1, z2, mu=mu)\n",
    "            optimizer_vicreg.zero_grad()\n",
    "            vicreg_loss_val.backward()\n",
    "            optimizer_vicreg.step()\n",
    "            try:\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            except StopIteration:\n",
    "                labeled_iterator = iter(labeled_dataloader)\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            labeled_img, humidity, class_label = labeled_img.to(device), humidity.to(device), class_label.to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = model(labeled_img, x_light=None)\n",
    "            pred_humidity = linear_reg(feat)\n",
    "            mse_loss = F.mse_loss(pred_humidity, humidity)\n",
    "            optimizer_linear.zero_grad()\n",
    "            mse_loss.backward()\n",
    "            optimizer_linear.step()\n",
    "            pred_logits = classifier(feat)\n",
    "            cls_loss = F.cross_entropy(pred_logits, class_label)\n",
    "            optimizer_classifier.zero_grad()\n",
    "            cls_loss.backward()\n",
    "            optimizer_classifier.step()\n",
    "            pred_humidity_np = pred_humidity.detach().cpu().numpy() * 100\n",
    "            humidity_np = humidity.detach().cpu().numpy() * 100\n",
    "            mse = mean_squared_error(humidity_np, pred_humidity_np)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(humidity_np, pred_humidity_np)\n",
    "            pred_classes = torch.argmax(pred_logits, dim=1).detach().cpu().numpy()\n",
    "            true_classes = class_label.detach().cpu().numpy()\n",
    "            accuracy = accuracy_score(true_classes, pred_classes)\n",
    "            f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "            running_vicreg_loss += vicreg_loss_val.item()\n",
    "            running_mse += mse\n",
    "            running_mae += mae\n",
    "            running_accuracy += accuracy\n",
    "            running_f1 += f1\n",
    "            num_batches += 1\n",
    "        avg_vicreg_loss = running_vicreg_loss / num_batches\n",
    "        avg_mse = running_mse / num_batches\n",
    "        avg_rmse = np.sqrt(avg_mse)\n",
    "        avg_mae = running_mae / num_batches\n",
    "        avg_accuracy = running_accuracy / num_batches\n",
    "        avg_f1 = running_f1 / num_batches\n",
    "        vicreg_losses.append(avg_vicreg_loss)\n",
    "        mse_losses.append(avg_mse)\n",
    "        rmse_losses.append(avg_rmse)\n",
    "        mae_losses.append(avg_mae)\n",
    "        accuracy_scores.append(avg_accuracy)\n",
    "        f1_scores.append(avg_f1)\n",
    "        \n",
    "        print(f\"✅ Epoch {epoch:3d}/{num_epochs} (mu={mu}) - VICReg Loss: {avg_vicreg_loss:.4f}, \"\n",
    "              f\"MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, \"\n",
    "              f\"Accuracy: {avg_accuracy:.8f}, F1-Score: {avg_f1:.8f}\")\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'projector_state_dict': projector.state_dict(),\n",
    "            'linear_reg_state_dict': linear_reg.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'vicreg_mu_{mu}_epoch_{epoch}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logging.info(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        final_model_path = os.path.join(checkpoint_dir, f'vicreg_model_final_mu_{mu}.pth')\n",
    "        final_projector_path = os.path.join(checkpoint_dir, f'vicreg_projector_final_mu_{mu}.pth')\n",
    "        final_linear_reg_path = os.path.join(checkpoint_dir, f'vicreg_linear_reg_final_mu_{mu}.pth')\n",
    "        final_classifier_path = os.path.join(checkpoint_dir, f'vicreg_classifier_final_mu_{mu}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        torch.save(projector.state_dict(), final_projector_path)\n",
    "        torch.save(linear_reg.state_dict(), final_linear_reg_path)\n",
    "        torch.save(classifier.state_dict(), final_classifier_path)\n",
    "        logging.info(f\"Saved final models (mu={mu}): {final_model_path}, {final_projector_path}, {final_linear_reg_path}, {final_classifier_path}\")\n",
    "        # Append metrics to DataFrame\n",
    "        metrics_df.append({\n",
    "            'mu': mu,\n",
    "            'epoch': epoch,\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        })\n",
    "\n",
    "# Initialize an empty list to collect metrics\n",
    "all_metrics = []\n",
    "#for mu_val in [20.0, 23.0, 25.0, 27.0, 30.0, 33.0]:\n",
    "for mu_val in [40.0]:\n",
    "    train_vicreg_with_mu(mu=mu_val, num_epochs=60, metrics_df=all_metrics)\n",
    "\n",
    "# Convert metrics to DataFrame and save to CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv(os.path.join(checkpoint_dir, 'vicreg_metrics.csv'), index=False)\n",
    "logging.info(f\"Saved metrics to {os.path.join(checkpoint_dir, 'import torch')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a98c5c-254c-4bf3-9959-4ae2df88a6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
