{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed2af90-41fe-421f-9437-c88c92c6a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6074e36-5ec1-418c-a3ed-7418a23fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Kiểm tra và đặt thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd6067-3711-4638-95c3-5a4091e0e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df):\n",
    "    new_df = df.copy()\n",
    "    deleted_count = 0\n",
    "    valid_indices = []\n",
    "    for idx, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "        path = row[\"path\"]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            valid_indices.append(idx)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    new_df = new_df.loc[valid_indices].reset_index(drop=True)\n",
    "    logging.info(f\"Deleted {deleted_count} labeled images. {len(new_df)} images remain.\")\n",
    "    return new_df\n",
    "\n",
    "def preprocess_unlabeled_images(image_paths):\n",
    "    new_image_paths = []\n",
    "    deleted_count = 0\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            new_image_paths.append(path)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    logging.info(f\"Deleted {deleted_count} unlabeled images. {len(new_image_paths)} images remain.\")\n",
    "    return new_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190a3635-2aaa-4852-8846-996eb51d127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2057/2057 [01:05<00:00, 31.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2052/2052 [01:04<00:00, 31.64it/s]\n"
     ]
    }
   ],
   "source": [
    "label_csv_path = r\"F:\\Soil_Labeled_Data\\labels.csv\"\n",
    "fallback_dir = r\"F:\\Soil_Labeled_Data\\augmented_fallback\"\n",
    "os.makedirs(fallback_dir, exist_ok=True)\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df = preprocess_images(df)\n",
    "\n",
    "augment = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "replaced_count = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    path = row[\"path\"]\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img.verify()\n",
    "    except (UnidentifiedImageError, FileNotFoundError, OSError):\n",
    "        folder = os.path.dirname(path)\n",
    "        all_images = [f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "        good_images = [f for f in all_images if f != os.path.basename(path)]\n",
    "        if not good_images:\n",
    "            continue\n",
    "        candidate = random.choice(good_images)\n",
    "        candidate_path = os.path.join(folder, candidate)\n",
    "        try:\n",
    "            img = Image.open(candidate_path).convert(\"RGB\")\n",
    "            img_aug = augment(img)\n",
    "            new_filename = f\"aug_{os.path.basename(path)}\"\n",
    "            new_path = os.path.join(fallback_dir, new_filename)\n",
    "            img_aug.save(new_path)\n",
    "            df.at[idx, \"path\"] = new_path\n",
    "            replaced_count += 1\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba635eb-f1dc-4fbd-a0d8-0227a00e0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11995/11995 [01:27<00:00, 137.25it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dir = r\"F:/unlabeled_images\"\n",
    "image_paths = []\n",
    "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"]:\n",
    "    image_paths.extend(glob.glob(os.path.join(image_dir, \"**\", ext), recursive=True))\n",
    "image_paths = preprocess_unlabeled_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96588c62-959b-4472-be0f-fbcc5eb1f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "labeled_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img1 = self.transform(image)\n",
    "            img2 = self.transform(image)\n",
    "            return img1, img2\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_paths))\n",
    "\n",
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(image)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        humidity = torch.tensor([row['SM_0'] / 100, row['SM_20'] / 100], dtype=torch.float32)\n",
    "        class_label = torch.tensor(row[\"moisture_class\"], dtype=torch.long)\n",
    "        return img, humidity, class_label\n",
    "\n",
    "unlabeled_dataset = UnlabeledImageDataset(image_paths, transform)\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "labeled_dataset = LabeledImageDataset(df, labeled_transform)\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "class SoilNetDualHead(nn.Module):\n",
    "    def __init__(self, num_classes=10, simclr_mode=False):\n",
    "        super().__init__()\n",
    "        self.simclr_mode = simclr_mode\n",
    "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.mnv2_block1 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[0:3]\n",
    "        )\n",
    "        self.channel_adapter = nn.Conv2d(32, 16, kernel_size=1, bias=False)\n",
    "        self.mobilevit_full = timm.create_model(\"mobilevitv2_050\", pretrained=True)\n",
    "        self.mobilevit_encoder = self.mobilevit_full.stages\n",
    "        self.mvit_to_mnv2 = nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "        self.mnv2_block2 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[3:7]\n",
    "        )\n",
    "        self.final_conv = nn.Conv2d(320, 1280, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.light_dense = nn.Sequential(nn.Linear(1, 32), nn.ReLU(inplace=True))\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_light=None):\n",
    "        x = self.initial_conv(x_img)\n",
    "        x = self.mnv2_block1(x)\n",
    "        x = self.channel_adapter(x)\n",
    "        x = self.mobilevit_encoder(x)\n",
    "        x = self.mvit_to_mnv2(x)\n",
    "        x = self.mnv2_block2(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.pool(x)\n",
    "        x_img_feat = torch.flatten(x, 1)\n",
    "        if self.simclr_mode:\n",
    "            return x_img_feat\n",
    "        x_light_feat = self.light_dense(x_light)\n",
    "        x_concat = torch.cat([x_img_feat, x_light_feat], dim=1)\n",
    "        reg_out = self.reg_head(x_concat)\n",
    "        cls_out = self.cls_head(x_concat)\n",
    "        return reg_out, cls_out\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, input_dim=1280, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class OnlineLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class OnlineClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def vicreg_loss(z1, z2, lambda_=25.0, mu=25.0, nu=1.0, epsilon=1e-4):\n",
    "    invariance_loss = F.mse_loss(z1, z2)\n",
    "    def variance_term(z):\n",
    "        z_std = torch.sqrt(z.var(dim=0) + epsilon)\n",
    "        return torch.mean(F.relu(1 - z_std))\n",
    "    var_loss = variance_term(z1) + variance_term(z2)\n",
    "    def covariance_term(z):\n",
    "        z = z - z.mean(dim=0)\n",
    "        cov = (z.T @ z) / (z.shape[0] - 1)\n",
    "        off_diag = cov - torch.diag(cov.diag())\n",
    "        return off_diag.pow(2).sum() / z.shape[1]\n",
    "    cov_loss = covariance_term(z1) + covariance_term(z2)\n",
    "    return lambda_ * invariance_loss + mu * var_loss + nu * cov_loss\n",
    "\n",
    "model = SoilNetDualHead(num_classes=10, simclr_mode=True).to(device)\n",
    "projector = Projector(input_dim=1280, proj_dim=128).to(device)\n",
    "linear_reg = OnlineLinearRegression(input_dim=1280, output_dim=2).to(device)\n",
    "classifier = OnlineClassifier(input_dim=1280, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89271f6e-e617-4fb5-84bf-ee8d8d7132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(r\"C:\\Users\\PC\\soilNet\\Model\\SoilNet_orginal.pth\", map_location=device))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "optimizer_vicreg = torch.optim.Adam(list(model.parameters()) + list(projector.parameters()), lr=1e-4)\n",
    "optimizer_linear = torch.optim.Adam(linear_reg.parameters(), lr=1e-3)\n",
    "optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "#checkpoint_dir = \"/content/drive/MyDrive/SoilNet_Checkpoints/checkpoints_VicReg\"\n",
    "checkpoint_dir = r\"C:\\Users\\PC\\soilNet\\checkpoints_VicReg\"\n",
    "\n",
    "#C:\\Users\\PC\\soilNet\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e040f89a-3f5e-47ed-ad72-c2edf6eff441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   1/60 (mu=25.0) - VICReg Loss: 36.0402, MSE: 1709.4032, RMSE: 41.3449, MAE: 31.7240, Accuracy: 0.17189586, F1-Score: 0.17481371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   2/60 (mu=25.0) - VICReg Loss: 34.3061, MSE: 1082.9583, RMSE: 32.9083, MAE: 26.4196, Accuracy: 0.17356475, F1-Score: 0.17571981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   3/60 (mu=25.0) - VICReg Loss: 32.7569, MSE: 980.4069, RMSE: 31.3115, MAE: 25.0829, Accuracy: 0.18266021, F1-Score: 0.18717009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   4/60 (mu=25.0) - VICReg Loss: 31.5325, MSE: 893.2699, RMSE: 29.8876, MAE: 23.9531, Accuracy: 0.19934913, F1-Score: 0.20146982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   5/60 (mu=25.0) - VICReg Loss: 30.4527, MSE: 869.9471, RMSE: 29.4949, MAE: 23.4885, Accuracy: 0.20235314, F1-Score: 0.20817534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   6/60 (mu=25.0) - VICReg Loss: 29.4647, MSE: 799.4951, RMSE: 28.2753, MAE: 22.5504, Accuracy: 0.21787383, F1-Score: 0.22214553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   7/60 (mu=25.0) - VICReg Loss: 28.3971, MSE: 792.2597, RMSE: 28.1471, MAE: 22.3663, Accuracy: 0.22847130, F1-Score: 0.23497097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   8/60 (mu=25.0) - VICReg Loss: 27.5669, MSE: 755.8672, RMSE: 27.4930, MAE: 21.9232, Accuracy: 0.23189252, F1-Score: 0.23331671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   9/60 (mu=25.0) - VICReg Loss: 26.6438, MSE: 779.5587, RMSE: 27.9206, MAE: 22.2198, Accuracy: 0.24040387, F1-Score: 0.24339087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  10/60 (mu=25.0) - VICReg Loss: 25.8960, MSE: 731.4738, RMSE: 27.0458, MAE: 21.4694, Accuracy: 0.23055741, F1-Score: 0.23417361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  11/60 (mu=25.0) - VICReg Loss: 24.8704, MSE: 766.2835, RMSE: 27.6818, MAE: 21.9969, Accuracy: 0.23940254, F1-Score: 0.24476246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  12/60 (mu=25.0) - VICReg Loss: 24.1305, MSE: 744.0909, RMSE: 27.2780, MAE: 21.6467, Accuracy: 0.24582777, F1-Score: 0.24890804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  13/60 (mu=25.0) - VICReg Loss: 23.4260, MSE: 782.3538, RMSE: 27.9706, MAE: 22.1598, Accuracy: 0.23915220, F1-Score: 0.24332266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  14/60 (mu=25.0) - VICReg Loss: 22.6212, MSE: 778.3698, RMSE: 27.8993, MAE: 22.2010, Accuracy: 0.23531375, F1-Score: 0.23893462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  15/60 (mu=25.0) - VICReg Loss: 22.0912, MSE: 761.7359, RMSE: 27.5996, MAE: 22.0556, Accuracy: 0.25083445, F1-Score: 0.25648019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  16/60 (mu=25.0) - VICReg Loss: 21.5244, MSE: 758.5480, RMSE: 27.5417, MAE: 22.0317, Accuracy: 0.24032043, F1-Score: 0.24254981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  17/60 (mu=25.0) - VICReg Loss: 20.9322, MSE: 777.1814, RMSE: 27.8780, MAE: 22.2442, Accuracy: 0.24115487, F1-Score: 0.24583174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  18/60 (mu=25.0) - VICReg Loss: 20.5495, MSE: 758.9085, RMSE: 27.5483, MAE: 22.0517, Accuracy: 0.24549399, F1-Score: 0.25193250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  19/60 (mu=25.0) - VICReg Loss: 20.2556, MSE: 764.8218, RMSE: 27.6554, MAE: 22.1339, Accuracy: 0.24599466, F1-Score: 0.24960966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  20/60 (mu=25.0) - VICReg Loss: 19.9254, MSE: 750.9356, RMSE: 27.4032, MAE: 22.0224, Accuracy: 0.25241989, F1-Score: 0.25626228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  21/60 (mu=25.0) - VICReg Loss: 19.5947, MSE: 785.8963, RMSE: 28.0338, MAE: 22.4596, Accuracy: 0.24599466, F1-Score: 0.24783273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  22/60 (mu=25.0) - VICReg Loss: 19.4156, MSE: 786.7586, RMSE: 28.0492, MAE: 22.4032, Accuracy: 0.25509012, F1-Score: 0.26017368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  23/60 (mu=25.0) - VICReg Loss: 19.2227, MSE: 787.7943, RMSE: 28.0677, MAE: 22.4839, Accuracy: 0.24516021, F1-Score: 0.24856522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  24/60 (mu=25.0) - VICReg Loss: 19.0339, MSE: 779.0319, RMSE: 27.9111, MAE: 22.2761, Accuracy: 0.25458945, F1-Score: 0.25781085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  25/60 (mu=25.0) - VICReg Loss: 18.9193, MSE: 797.6633, RMSE: 28.2429, MAE: 22.5883, Accuracy: 0.25025033, F1-Score: 0.25411115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  26/60 (mu=25.0) - VICReg Loss: 18.7176, MSE: 779.9304, RMSE: 27.9272, MAE: 22.3486, Accuracy: 0.25258678, F1-Score: 0.25713517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  27/60 (mu=25.0) - VICReg Loss: 18.6047, MSE: 791.7345, RMSE: 28.1378, MAE: 22.4748, Accuracy: 0.24833111, F1-Score: 0.25235015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  28/60 (mu=25.0) - VICReg Loss: 18.5139, MSE: 777.1225, RMSE: 27.8769, MAE: 22.3716, Accuracy: 0.25325434, F1-Score: 0.25758570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  29/60 (mu=25.0) - VICReg Loss: 18.3885, MSE: 809.5993, RMSE: 28.4535, MAE: 22.7793, Accuracy: 0.24866489, F1-Score: 0.25378108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  30/60 (mu=25.0) - VICReg Loss: 18.2673, MSE: 811.4891, RMSE: 28.4866, MAE: 22.7357, Accuracy: 0.25634179, F1-Score: 0.25869201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  31/60 (mu=25.0) - VICReg Loss: 18.1870, MSE: 811.2449, RMSE: 28.4824, MAE: 22.8530, Accuracy: 0.25859479, F1-Score: 0.26213435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  32/60 (mu=25.0) - VICReg Loss: 18.1115, MSE: 799.9129, RMSE: 28.2827, MAE: 22.7221, Accuracy: 0.25375501, F1-Score: 0.25643133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  33/60 (mu=25.0) - VICReg Loss: 18.1223, MSE: 826.1661, RMSE: 28.7431, MAE: 23.0252, Accuracy: 0.24941589, F1-Score: 0.25373493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  34/60 (mu=25.0) - VICReg Loss: 17.9721, MSE: 866.4992, RMSE: 29.4364, MAE: 23.6182, Accuracy: 0.24916555, F1-Score: 0.25130280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  35/60 (mu=25.0) - VICReg Loss: 17.9399, MSE: 880.5283, RMSE: 29.6737, MAE: 23.8121, Accuracy: 0.24883178, F1-Score: 0.25430760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  36/60 (mu=25.0) - VICReg Loss: 17.8530, MSE: 846.5662, RMSE: 29.0958, MAE: 23.3665, Accuracy: 0.24699599, F1-Score: 0.24964560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  37/60 (mu=25.0) - VICReg Loss: 17.8240, MSE: 841.1977, RMSE: 29.0034, MAE: 23.3652, Accuracy: 0.24474299, F1-Score: 0.24725812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  38/60 (mu=25.0) - VICReg Loss: 17.6391, MSE: 838.6713, RMSE: 28.9598, MAE: 23.3127, Accuracy: 0.24732977, F1-Score: 0.25114608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  39/60 (mu=25.0) - VICReg Loss: 17.7366, MSE: 833.9331, RMSE: 28.8779, MAE: 23.2674, Accuracy: 0.25492323, F1-Score: 0.25907798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  40/60 (mu=25.0) - VICReg Loss: 17.6474, MSE: 878.7569, RMSE: 29.6438, MAE: 23.9073, Accuracy: 0.24749666, F1-Score: 0.25086611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  41/60 (mu=25.0) - VICReg Loss: 17.5915, MSE: 843.9177, RMSE: 29.0503, MAE: 23.4633, Accuracy: 0.24983311, F1-Score: 0.25307805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  42/60 (mu=25.0) - VICReg Loss: 17.5235, MSE: 870.4682, RMSE: 29.5037, MAE: 23.7185, Accuracy: 0.25342123, F1-Score: 0.25722935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  43/60 (mu=25.0) - VICReg Loss: 17.6086, MSE: 888.4611, RMSE: 29.8071, MAE: 24.0416, Accuracy: 0.24173899, F1-Score: 0.24544022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  44/60 (mu=25.0) - VICReg Loss: 17.4315, MSE: 842.8769, RMSE: 29.0323, MAE: 23.3282, Accuracy: 0.25133511, F1-Score: 0.25430018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  45/60 (mu=25.0) - VICReg Loss: 17.4911, MSE: 860.2211, RMSE: 29.3295, MAE: 23.6459, Accuracy: 0.23940254, F1-Score: 0.24343450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  46/60 (mu=25.0) - VICReg Loss: 17.3590, MSE: 876.1255, RMSE: 29.5994, MAE: 23.7645, Accuracy: 0.24490988, F1-Score: 0.24736070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  47/60 (mu=25.0) - VICReg Loss: 17.4079, MSE: 882.4578, RMSE: 29.7062, MAE: 23.8969, Accuracy: 0.24933244, F1-Score: 0.25309040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  48/60 (mu=25.0) - VICReg Loss: 17.3631, MSE: 871.6342, RMSE: 29.5235, MAE: 23.6995, Accuracy: 0.24591121, F1-Score: 0.24855581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  49/60 (mu=25.0) - VICReg Loss: 17.3533, MSE: 890.8651, RMSE: 29.8474, MAE: 24.0588, Accuracy: 0.24190587, F1-Score: 0.24436001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  50/60 (mu=25.0) - VICReg Loss: 17.2428, MSE: 902.5790, RMSE: 30.0430, MAE: 24.1753, Accuracy: 0.24324099, F1-Score: 0.24447835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  51/60 (mu=25.0) - VICReg Loss: 17.3315, MSE: 913.1761, RMSE: 30.2188, MAE: 24.2741, Accuracy: 0.23689920, F1-Score: 0.23913525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  52/60 (mu=25.0) - VICReg Loss: 17.1766, MSE: 882.5606, RMSE: 29.7079, MAE: 23.8532, Accuracy: 0.24616155, F1-Score: 0.24750275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  53/60 (mu=25.0) - VICReg Loss: 17.2220, MSE: 883.5450, RMSE: 29.7245, MAE: 23.8272, Accuracy: 0.24440921, F1-Score: 0.24511410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  54/60 (mu=25.0) - VICReg Loss: 17.1287, MSE: 882.9689, RMSE: 29.7148, MAE: 23.8877, Accuracy: 0.23973632, F1-Score: 0.24214468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  55/60 (mu=25.0) - VICReg Loss: 17.2023, MSE: 903.8860, RMSE: 30.0647, MAE: 24.2305, Accuracy: 0.23990320, F1-Score: 0.24065272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  56/60 (mu=25.0) - VICReg Loss: 17.0521, MSE: 921.5951, RMSE: 30.3578, MAE: 24.4400, Accuracy: 0.24541055, F1-Score: 0.24628258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  57/60 (mu=25.0) - VICReg Loss: 17.1120, MSE: 905.6130, RMSE: 30.0934, MAE: 24.2509, Accuracy: 0.23873498, F1-Score: 0.24160640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  58/60 (mu=25.0) - VICReg Loss: 17.0208, MSE: 890.7763, RMSE: 29.8459, MAE: 24.0811, Accuracy: 0.24382510, F1-Score: 0.24462418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  59/60 (mu=25.0) - VICReg Loss: 17.0932, MSE: 916.3622, RMSE: 30.2715, MAE: 24.4180, Accuracy: 0.24432577, F1-Score: 0.24653758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  60/60 (mu=25.0) - VICReg Loss: 17.1136, MSE: 907.9344, RMSE: 30.1319, MAE: 24.2610, Accuracy: 0.23890187, F1-Score: 0.23885661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def train_vicreg_with_mu(mu=25.0, num_epochs=150, metrics_df=None):\n",
    "    vicreg_losses, mse_losses, rmse_losses, mae_losses, accuracy_scores, f1_scores = [], [], [], [], [], []\n",
    "    labeled_iterator = iter(labeled_dataloader)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        projector.train()\n",
    "        linear_reg.train()\n",
    "        classifier.train()\n",
    "        running_vicreg_loss = running_mse = running_mae = running_accuracy = running_f1 = 0.0\n",
    "        num_batches = 0\n",
    "        for img1, img2 in tqdm(unlabeled_dataloader, leave=False):\n",
    "            img1, img2 = img1.to(device), img2.to(device)\n",
    "            feat1 = model(img1, x_light=None)\n",
    "            feat2 = model(img2, x_light=None)\n",
    "            z1 = projector(feat1)\n",
    "            z2 = projector(feat2)\n",
    "            vicreg_loss_val = vicreg_loss(z1, z2, mu=mu)\n",
    "            optimizer_vicreg.zero_grad()\n",
    "            vicreg_loss_val.backward()\n",
    "            optimizer_vicreg.step()\n",
    "            try:\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            except StopIteration:\n",
    "                labeled_iterator = iter(labeled_dataloader)\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            labeled_img, humidity, class_label = labeled_img.to(device), humidity.to(device), class_label.to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = model(labeled_img, x_light=None)\n",
    "            pred_humidity = linear_reg(feat)\n",
    "            mse_loss = F.mse_loss(pred_humidity, humidity)\n",
    "            optimizer_linear.zero_grad()\n",
    "            mse_loss.backward()\n",
    "            optimizer_linear.step()\n",
    "            pred_logits = classifier(feat)\n",
    "            cls_loss = F.cross_entropy(pred_logits, class_label)\n",
    "            optimizer_classifier.zero_grad()\n",
    "            cls_loss.backward()\n",
    "            optimizer_classifier.step()\n",
    "            pred_humidity_np = pred_humidity.detach().cpu().numpy() * 100\n",
    "            humidity_np = humidity.detach().cpu().numpy() * 100\n",
    "            mse = mean_squared_error(humidity_np, pred_humidity_np)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(humidity_np, pred_humidity_np)\n",
    "            pred_classes = torch.argmax(pred_logits, dim=1).detach().cpu().numpy()\n",
    "            true_classes = class_label.detach().cpu().numpy()\n",
    "            accuracy = accuracy_score(true_classes, pred_classes)\n",
    "            f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "            running_vicreg_loss += vicreg_loss_val.item()\n",
    "            running_mse += mse\n",
    "            running_mae += mae\n",
    "            running_accuracy += accuracy\n",
    "            running_f1 += f1\n",
    "            num_batches += 1\n",
    "        avg_vicreg_loss = running_vicreg_loss / num_batches\n",
    "        avg_mse = running_mse / num_batches\n",
    "        avg_rmse = np.sqrt(avg_mse)\n",
    "        avg_mae = running_mae / num_batches\n",
    "        avg_accuracy = running_accuracy / num_batches\n",
    "        avg_f1 = running_f1 / num_batches\n",
    "        vicreg_losses.append(avg_vicreg_loss)\n",
    "        mse_losses.append(avg_mse)\n",
    "        rmse_losses.append(avg_rmse)\n",
    "        mae_losses.append(avg_mae)\n",
    "        accuracy_scores.append(avg_accuracy)\n",
    "        f1_scores.append(avg_f1)\n",
    "        \n",
    "        print(f\"✅ Epoch {epoch:3d}/{num_epochs} (mu={mu}) - VICReg Loss: {avg_vicreg_loss:.4f}, \"\n",
    "              f\"MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, \"\n",
    "              f\"Accuracy: {avg_accuracy:.8f}, F1-Score: {avg_f1:.8f}\")\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'projector_state_dict': projector.state_dict(),\n",
    "            'linear_reg_state_dict': linear_reg.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'vicreg_mu_{mu}_epoch_{epoch}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logging.info(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        final_model_path = os.path.join(checkpoint_dir, f'vicreg_model_final_mu_{mu}.pth')\n",
    "        final_projector_path = os.path.join(checkpoint_dir, f'vicreg_projector_final_mu_{mu}.pth')\n",
    "        final_linear_reg_path = os.path.join(checkpoint_dir, f'vicreg_linear_reg_final_mu_{mu}.pth')\n",
    "        final_classifier_path = os.path.join(checkpoint_dir, f'vicreg_classifier_final_mu_{mu}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        torch.save(projector.state_dict(), final_projector_path)\n",
    "        torch.save(linear_reg.state_dict(), final_linear_reg_path)\n",
    "        torch.save(classifier.state_dict(), final_classifier_path)\n",
    "        logging.info(f\"Saved final models (mu={mu}): {final_model_path}, {final_projector_path}, {final_linear_reg_path}, {final_classifier_path}\")\n",
    "        # Append metrics to DataFrame\n",
    "        metrics_df.append({\n",
    "            'mu': mu,\n",
    "            'epoch': epoch,\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        })\n",
    "\n",
    "# Initialize an empty list to collect metrics\n",
    "all_metrics = []\n",
    "#for mu_val in [20.0, 23.0, 25.0, 27.0, 30.0, 33.0]:\n",
    "for mu_val in [25.0]:\n",
    "    train_vicreg_with_mu(mu=mu_val, num_epochs=60, metrics_df=all_metrics)\n",
    "\n",
    "# Convert metrics to DataFrame and save to CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv(os.path.join(checkpoint_dir, 'vicreg_metrics.csv'), index=False)\n",
    "logging.info(f\"Saved metrics to {os.path.join(checkpoint_dir, 'import torch')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a98c5c-254c-4bf3-9959-4ae2df88a6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
