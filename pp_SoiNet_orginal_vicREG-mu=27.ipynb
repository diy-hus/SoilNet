{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed2af90-41fe-421f-9437-c88c92c6a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6074e36-5ec1-418c-a3ed-7418a23fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Kiểm tra và đặt thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd6067-3711-4638-95c3-5a4091e0e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df):\n",
    "    new_df = df.copy()\n",
    "    deleted_count = 0\n",
    "    valid_indices = []\n",
    "    for idx, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "        path = row[\"path\"]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            valid_indices.append(idx)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    new_df = new_df.loc[valid_indices].reset_index(drop=True)\n",
    "    logging.info(f\"Deleted {deleted_count} labeled images. {len(new_df)} images remain.\")\n",
    "    return new_df\n",
    "\n",
    "def preprocess_unlabeled_images(image_paths):\n",
    "    new_image_paths = []\n",
    "    deleted_count = 0\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            new_image_paths.append(path)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    logging.info(f\"Deleted {deleted_count} unlabeled images. {len(new_image_paths)} images remain.\")\n",
    "    return new_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190a3635-2aaa-4852-8846-996eb51d127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2057/2057 [01:23<00:00, 24.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2052/2052 [01:05<00:00, 31.15it/s]\n"
     ]
    }
   ],
   "source": [
    "label_csv_path = r\"F:\\Soil_Labeled_Data\\labels.csv\"\n",
    "fallback_dir = r\"F:\\Soil_Labeled_Data\\augmented_fallback\"\n",
    "os.makedirs(fallback_dir, exist_ok=True)\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df = preprocess_images(df)\n",
    "\n",
    "augment = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "replaced_count = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    path = row[\"path\"]\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img.verify()\n",
    "    except (UnidentifiedImageError, FileNotFoundError, OSError):\n",
    "        folder = os.path.dirname(path)\n",
    "        all_images = [f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "        good_images = [f for f in all_images if f != os.path.basename(path)]\n",
    "        if not good_images:\n",
    "            continue\n",
    "        candidate = random.choice(good_images)\n",
    "        candidate_path = os.path.join(folder, candidate)\n",
    "        try:\n",
    "            img = Image.open(candidate_path).convert(\"RGB\")\n",
    "            img_aug = augment(img)\n",
    "            new_filename = f\"aug_{os.path.basename(path)}\"\n",
    "            new_path = os.path.join(fallback_dir, new_filename)\n",
    "            img_aug.save(new_path)\n",
    "            df.at[idx, \"path\"] = new_path\n",
    "            replaced_count += 1\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba635eb-f1dc-4fbd-a0d8-0227a00e0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11995/11995 [02:26<00:00, 82.09it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dir = r\"F:/unlabeled_images\"\n",
    "image_paths = []\n",
    "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"]:\n",
    "    image_paths.extend(glob.glob(os.path.join(image_dir, \"**\", ext), recursive=True))\n",
    "image_paths = preprocess_unlabeled_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96588c62-959b-4472-be0f-fbcc5eb1f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "labeled_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img1 = self.transform(image)\n",
    "            img2 = self.transform(image)\n",
    "            return img1, img2\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_paths))\n",
    "\n",
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(image)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        humidity = torch.tensor([row['SM_0'] / 100, row['SM_20'] / 100], dtype=torch.float32)\n",
    "        class_label = torch.tensor(row[\"moisture_class\"], dtype=torch.long)\n",
    "        return img, humidity, class_label\n",
    "\n",
    "unlabeled_dataset = UnlabeledImageDataset(image_paths, transform)\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "labeled_dataset = LabeledImageDataset(df, labeled_transform)\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "class SoilNetDualHead(nn.Module):\n",
    "    def __init__(self, num_classes=10, simclr_mode=False):\n",
    "        super().__init__()\n",
    "        self.simclr_mode = simclr_mode\n",
    "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.mnv2_block1 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[0:3]\n",
    "        )\n",
    "        self.channel_adapter = nn.Conv2d(32, 16, kernel_size=1, bias=False)\n",
    "        self.mobilevit_full = timm.create_model(\"mobilevitv2_050\", pretrained=True)\n",
    "        self.mobilevit_encoder = self.mobilevit_full.stages\n",
    "        self.mvit_to_mnv2 = nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "        self.mnv2_block2 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[3:7]\n",
    "        )\n",
    "        self.final_conv = nn.Conv2d(320, 1280, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.light_dense = nn.Sequential(nn.Linear(1, 32), nn.ReLU(inplace=True))\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_light=None):\n",
    "        x = self.initial_conv(x_img)\n",
    "        x = self.mnv2_block1(x)\n",
    "        x = self.channel_adapter(x)\n",
    "        x = self.mobilevit_encoder(x)\n",
    "        x = self.mvit_to_mnv2(x)\n",
    "        x = self.mnv2_block2(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.pool(x)\n",
    "        x_img_feat = torch.flatten(x, 1)\n",
    "        if self.simclr_mode:\n",
    "            return x_img_feat\n",
    "        x_light_feat = self.light_dense(x_light)\n",
    "        x_concat = torch.cat([x_img_feat, x_light_feat], dim=1)\n",
    "        reg_out = self.reg_head(x_concat)\n",
    "        cls_out = self.cls_head(x_concat)\n",
    "        return reg_out, cls_out\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, input_dim=1280, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class OnlineLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class OnlineClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def vicreg_loss(z1, z2, lambda_=25.0, mu=25.0, nu=1.0, epsilon=1e-4):\n",
    "    invariance_loss = F.mse_loss(z1, z2)\n",
    "    def variance_term(z):\n",
    "        z_std = torch.sqrt(z.var(dim=0) + epsilon)\n",
    "        return torch.mean(F.relu(1 - z_std))\n",
    "    var_loss = variance_term(z1) + variance_term(z2)\n",
    "    def covariance_term(z):\n",
    "        z = z - z.mean(dim=0)\n",
    "        cov = (z.T @ z) / (z.shape[0] - 1)\n",
    "        off_diag = cov - torch.diag(cov.diag())\n",
    "        return off_diag.pow(2).sum() / z.shape[1]\n",
    "    cov_loss = covariance_term(z1) + covariance_term(z2)\n",
    "    return lambda_ * invariance_loss + mu * var_loss + nu * cov_loss\n",
    "\n",
    "model = SoilNetDualHead(num_classes=10, simclr_mode=True).to(device)\n",
    "projector = Projector(input_dim=1280, proj_dim=128).to(device)\n",
    "linear_reg = OnlineLinearRegression(input_dim=1280, output_dim=2).to(device)\n",
    "classifier = OnlineClassifier(input_dim=1280, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89271f6e-e617-4fb5-84bf-ee8d8d7132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(r\"C:\\Users\\PC\\soilNet\\Model\\SoilNet_orginal.pth\", map_location=device))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "optimizer_vicreg = torch.optim.Adam(list(model.parameters()) + list(projector.parameters()), lr=1e-4)\n",
    "optimizer_linear = torch.optim.Adam(linear_reg.parameters(), lr=1e-3)\n",
    "optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "#checkpoint_dir = \"/content/drive/MyDrive/SoilNet_Checkpoints/checkpoints_VicReg\"\n",
    "checkpoint_dir = r\"C:\\Users\\PC\\soilNet\\checkpoints_VicReg\"\n",
    "\n",
    "#C:\\Users\\PC\\soilNet\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e040f89a-3f5e-47ed-ad72-c2edf6eff441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   1/60 (mu=27.0) - VICReg Loss: 38.0775, MSE: 1718.2868, RMSE: 41.4522, MAE: 31.9504, Accuracy: 0.17848798, F1-Score: 0.17975607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   2/60 (mu=27.0) - VICReg Loss: 36.3009, MSE: 1120.0895, RMSE: 33.4677, MAE: 26.7962, Accuracy: 0.19133845, F1-Score: 0.19654327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   3/60 (mu=27.0) - VICReg Loss: 35.1128, MSE: 1053.1618, RMSE: 32.4525, MAE: 25.9559, Accuracy: 0.19943258, F1-Score: 0.20447872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   4/60 (mu=27.0) - VICReg Loss: 33.8521, MSE: 903.4059, RMSE: 30.0567, MAE: 24.1289, Accuracy: 0.21136515, F1-Score: 0.21690431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   5/60 (mu=27.0) - VICReg Loss: 32.5708, MSE: 819.0111, RMSE: 28.6184, MAE: 22.8315, Accuracy: 0.21770694, F1-Score: 0.21909318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   6/60 (mu=27.0) - VICReg Loss: 31.6739, MSE: 805.9687, RMSE: 28.3896, MAE: 22.6369, Accuracy: 0.22246328, F1-Score: 0.22820189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   7/60 (mu=27.0) - VICReg Loss: 30.5069, MSE: 758.8989, RMSE: 27.5481, MAE: 21.9190, Accuracy: 0.23230975, F1-Score: 0.23568872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   8/60 (mu=27.0) - VICReg Loss: 29.4140, MSE: 737.1125, RMSE: 27.1498, MAE: 21.6028, Accuracy: 0.23514686, F1-Score: 0.23769013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   9/60 (mu=27.0) - VICReg Loss: 28.3291, MSE: 736.5257, RMSE: 27.1390, MAE: 21.5619, Accuracy: 0.23397864, F1-Score: 0.23723821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  10/60 (mu=27.0) - VICReg Loss: 27.2854, MSE: 733.2495, RMSE: 27.0786, MAE: 21.4392, Accuracy: 0.23948598, F1-Score: 0.24407340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  11/60 (mu=27.0) - VICReg Loss: 26.2649, MSE: 713.9712, RMSE: 26.7202, MAE: 21.1622, Accuracy: 0.24457610, F1-Score: 0.24885636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  12/60 (mu=27.0) - VICReg Loss: 25.2311, MSE: 713.7145, RMSE: 26.7154, MAE: 21.1815, Accuracy: 0.24849800, F1-Score: 0.25496303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  13/60 (mu=27.0) - VICReg Loss: 24.2868, MSE: 679.4915, RMSE: 26.0671, MAE: 20.6425, Accuracy: 0.25125167, F1-Score: 0.25400488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  14/60 (mu=27.0) - VICReg Loss: 23.6551, MSE: 700.5706, RMSE: 26.4683, MAE: 21.0314, Accuracy: 0.25166889, F1-Score: 0.25597198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  15/60 (mu=27.0) - VICReg Loss: 22.9625, MSE: 674.9912, RMSE: 25.9806, MAE: 20.6348, Accuracy: 0.26201602, F1-Score: 0.26430030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  16/60 (mu=27.0) - VICReg Loss: 22.6463, MSE: 708.0224, RMSE: 26.6087, MAE: 21.1096, Accuracy: 0.25609146, F1-Score: 0.25984301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  17/60 (mu=27.0) - VICReg Loss: 21.9029, MSE: 691.3097, RMSE: 26.2928, MAE: 20.8892, Accuracy: 0.25400534, F1-Score: 0.25716763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  18/60 (mu=27.0) - VICReg Loss: 21.5202, MSE: 719.4513, RMSE: 26.8226, MAE: 21.4046, Accuracy: 0.26844126, F1-Score: 0.27187794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  19/60 (mu=27.0) - VICReg Loss: 21.0118, MSE: 732.7205, RMSE: 27.0688, MAE: 21.6124, Accuracy: 0.26451936, F1-Score: 0.27157751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  20/60 (mu=27.0) - VICReg Loss: 20.6311, MSE: 732.6721, RMSE: 27.0679, MAE: 21.5733, Accuracy: 0.27344793, F1-Score: 0.27528643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  21/60 (mu=27.0) - VICReg Loss: 20.3246, MSE: 725.9506, RMSE: 26.9435, MAE: 21.5388, Accuracy: 0.26401869, F1-Score: 0.26829720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  22/60 (mu=27.0) - VICReg Loss: 20.1274, MSE: 741.8176, RMSE: 27.2363, MAE: 21.7861, Accuracy: 0.26894192, F1-Score: 0.27450741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  23/60 (mu=27.0) - VICReg Loss: 19.8829, MSE: 773.7950, RMSE: 27.8172, MAE: 22.2132, Accuracy: 0.26268358, F1-Score: 0.26597993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  24/60 (mu=27.0) - VICReg Loss: 19.6674, MSE: 779.2659, RMSE: 27.9153, MAE: 22.3705, Accuracy: 0.25826101, F1-Score: 0.26332915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  25/60 (mu=27.0) - VICReg Loss: 19.5317, MSE: 795.6294, RMSE: 28.2069, MAE: 22.5782, Accuracy: 0.25675901, F1-Score: 0.26076733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  26/60 (mu=27.0) - VICReg Loss: 19.4222, MSE: 758.8602, RMSE: 27.5474, MAE: 21.8924, Accuracy: 0.26502003, F1-Score: 0.26746429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  27/60 (mu=27.0) - VICReg Loss: 19.2013, MSE: 782.6360, RMSE: 27.9756, MAE: 22.3436, Accuracy: 0.25592457, F1-Score: 0.25982359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  28/60 (mu=27.0) - VICReg Loss: 19.1348, MSE: 800.3763, RMSE: 28.2909, MAE: 22.6422, Accuracy: 0.26184913, F1-Score: 0.26605041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  29/60 (mu=27.0) - VICReg Loss: 18.9661, MSE: 784.9203, RMSE: 28.0164, MAE: 22.5020, Accuracy: 0.25876168, F1-Score: 0.26190430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  30/60 (mu=27.0) - VICReg Loss: 18.9174, MSE: 801.5477, RMSE: 28.3116, MAE: 22.6014, Accuracy: 0.25650868, F1-Score: 0.25951781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  31/60 (mu=27.0) - VICReg Loss: 18.7915, MSE: 776.3200, RMSE: 27.8625, MAE: 22.3634, Accuracy: 0.25650868, F1-Score: 0.25809148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  32/60 (mu=27.0) - VICReg Loss: 18.6295, MSE: 801.0474, RMSE: 28.3028, MAE: 22.6538, Accuracy: 0.25408879, F1-Score: 0.25992746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  33/60 (mu=27.0) - VICReg Loss: 18.5220, MSE: 796.3987, RMSE: 28.2205, MAE: 22.5887, Accuracy: 0.26502003, F1-Score: 0.26984860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  34/60 (mu=27.0) - VICReg Loss: 18.5279, MSE: 805.0062, RMSE: 28.3726, MAE: 22.7159, Accuracy: 0.25600801, F1-Score: 0.25941947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  35/60 (mu=27.0) - VICReg Loss: 18.4833, MSE: 823.6452, RMSE: 28.6992, MAE: 23.0393, Accuracy: 0.25317089, F1-Score: 0.25606749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  36/60 (mu=27.0) - VICReg Loss: 18.4443, MSE: 842.5027, RMSE: 29.0259, MAE: 23.2329, Accuracy: 0.25742657, F1-Score: 0.26048137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  37/60 (mu=27.0) - VICReg Loss: 18.2445, MSE: 822.4893, RMSE: 28.6791, MAE: 22.9990, Accuracy: 0.25325434, F1-Score: 0.25747043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  38/60 (mu=27.0) - VICReg Loss: 18.2662, MSE: 863.8807, RMSE: 29.3918, MAE: 23.5703, Accuracy: 0.25609146, F1-Score: 0.25986156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  39/60 (mu=27.0) - VICReg Loss: 18.1929, MSE: 811.7095, RMSE: 28.4905, MAE: 22.8443, Accuracy: 0.25308745, F1-Score: 0.25726789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  40/60 (mu=27.0) - VICReg Loss: 18.1602, MSE: 835.4403, RMSE: 28.9040, MAE: 23.2045, Accuracy: 0.24641188, F1-Score: 0.24663757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  41/60 (mu=27.0) - VICReg Loss: 18.1390, MSE: 846.9882, RMSE: 29.1031, MAE: 23.3365, Accuracy: 0.25317089, F1-Score: 0.25414872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  42/60 (mu=27.0) - VICReg Loss: 18.1218, MSE: 860.6905, RMSE: 29.3375, MAE: 23.6157, Accuracy: 0.25000000, F1-Score: 0.25410733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  43/60 (mu=27.0) - VICReg Loss: 18.0761, MSE: 820.7469, RMSE: 28.6487, MAE: 23.0943, Accuracy: 0.24866489, F1-Score: 0.25055909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  44/60 (mu=27.0) - VICReg Loss: 17.9628, MSE: 853.6998, RMSE: 29.2181, MAE: 23.4415, Accuracy: 0.24641188, F1-Score: 0.24882449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  45/60 (mu=27.0) - VICReg Loss: 17.9897, MSE: 877.4522, RMSE: 29.6218, MAE: 23.7486, Accuracy: 0.24766355, F1-Score: 0.24926443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  46/60 (mu=27.0) - VICReg Loss: 17.9237, MSE: 835.9705, RMSE: 28.9132, MAE: 23.2304, Accuracy: 0.24891522, F1-Score: 0.24990251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  47/60 (mu=27.0) - VICReg Loss: 17.9723, MSE: 851.5206, RMSE: 29.1808, MAE: 23.4460, Accuracy: 0.25317089, F1-Score: 0.25420466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  48/60 (mu=27.0) - VICReg Loss: 17.8349, MSE: 837.2405, RMSE: 28.9351, MAE: 23.1482, Accuracy: 0.26101469, F1-Score: 0.26463472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  49/60 (mu=27.0) - VICReg Loss: 17.7642, MSE: 862.6480, RMSE: 29.3709, MAE: 23.4891, Accuracy: 0.24991656, F1-Score: 0.25314232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  50/60 (mu=27.0) - VICReg Loss: 17.7794, MSE: 855.2857, RMSE: 29.2453, MAE: 23.4931, Accuracy: 0.24858144, F1-Score: 0.24990040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  51/60 (mu=27.0) - VICReg Loss: 17.7430, MSE: 894.5747, RMSE: 29.9094, MAE: 24.0118, Accuracy: 0.24374166, F1-Score: 0.24553395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  52/60 (mu=27.0) - VICReg Loss: 17.7374, MSE: 867.0958, RMSE: 29.4465, MAE: 23.6808, Accuracy: 0.24766355, F1-Score: 0.25109498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  53/60 (mu=27.0) - VICReg Loss: 17.7299, MSE: 871.2219, RMSE: 29.5165, MAE: 23.7257, Accuracy: 0.24808077, F1-Score: 0.24903886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  54/60 (mu=27.0) - VICReg Loss: 17.6871, MSE: 878.2920, RMSE: 29.6360, MAE: 23.8535, Accuracy: 0.24307410, F1-Score: 0.24458393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  55/60 (mu=27.0) - VICReg Loss: 17.6644, MSE: 853.8992, RMSE: 29.2216, MAE: 23.5247, Accuracy: 0.24382510, F1-Score: 0.24422504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  56/60 (mu=27.0) - VICReg Loss: 17.5994, MSE: 881.3482, RMSE: 29.6875, MAE: 23.9135, Accuracy: 0.24616155, F1-Score: 0.24622327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  57/60 (mu=27.0) - VICReg Loss: 17.7908, MSE: 920.5179, RMSE: 30.3400, MAE: 24.4671, Accuracy: 0.24265688, F1-Score: 0.24324282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  58/60 (mu=27.0) - VICReg Loss: 17.5768, MSE: 901.6256, RMSE: 30.0271, MAE: 24.2114, Accuracy: 0.24357477, F1-Score: 0.24349947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  59/60 (mu=27.0) - VICReg Loss: 17.5801, MSE: 939.9267, RMSE: 30.6582, MAE: 24.6245, Accuracy: 0.24232310, F1-Score: 0.24482807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  60/60 (mu=27.0) - VICReg Loss: 17.5428, MSE: 907.1887, RMSE: 30.1196, MAE: 24.2353, Accuracy: 0.23940254, F1-Score: 0.23993751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def train_vicreg_with_mu(mu=25.0, num_epochs=150, metrics_df=None):\n",
    "    vicreg_losses, mse_losses, rmse_losses, mae_losses, accuracy_scores, f1_scores = [], [], [], [], [], []\n",
    "    labeled_iterator = iter(labeled_dataloader)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        projector.train()\n",
    "        linear_reg.train()\n",
    "        classifier.train()\n",
    "        running_vicreg_loss = running_mse = running_mae = running_accuracy = running_f1 = 0.0\n",
    "        num_batches = 0\n",
    "        for img1, img2 in tqdm(unlabeled_dataloader, leave=False):\n",
    "            img1, img2 = img1.to(device), img2.to(device)\n",
    "            feat1 = model(img1, x_light=None)\n",
    "            feat2 = model(img2, x_light=None)\n",
    "            z1 = projector(feat1)\n",
    "            z2 = projector(feat2)\n",
    "            vicreg_loss_val = vicreg_loss(z1, z2, mu=mu)\n",
    "            optimizer_vicreg.zero_grad()\n",
    "            vicreg_loss_val.backward()\n",
    "            optimizer_vicreg.step()\n",
    "            try:\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            except StopIteration:\n",
    "                labeled_iterator = iter(labeled_dataloader)\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            labeled_img, humidity, class_label = labeled_img.to(device), humidity.to(device), class_label.to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = model(labeled_img, x_light=None)\n",
    "            pred_humidity = linear_reg(feat)\n",
    "            mse_loss = F.mse_loss(pred_humidity, humidity)\n",
    "            optimizer_linear.zero_grad()\n",
    "            mse_loss.backward()\n",
    "            optimizer_linear.step()\n",
    "            pred_logits = classifier(feat)\n",
    "            cls_loss = F.cross_entropy(pred_logits, class_label)\n",
    "            optimizer_classifier.zero_grad()\n",
    "            cls_loss.backward()\n",
    "            optimizer_classifier.step()\n",
    "            pred_humidity_np = pred_humidity.detach().cpu().numpy() * 100\n",
    "            humidity_np = humidity.detach().cpu().numpy() * 100\n",
    "            mse = mean_squared_error(humidity_np, pred_humidity_np)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(humidity_np, pred_humidity_np)\n",
    "            pred_classes = torch.argmax(pred_logits, dim=1).detach().cpu().numpy()\n",
    "            true_classes = class_label.detach().cpu().numpy()\n",
    "            accuracy = accuracy_score(true_classes, pred_classes)\n",
    "            f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "            running_vicreg_loss += vicreg_loss_val.item()\n",
    "            running_mse += mse\n",
    "            running_mae += mae\n",
    "            running_accuracy += accuracy\n",
    "            running_f1 += f1\n",
    "            num_batches += 1\n",
    "        avg_vicreg_loss = running_vicreg_loss / num_batches\n",
    "        avg_mse = running_mse / num_batches\n",
    "        avg_rmse = np.sqrt(avg_mse)\n",
    "        avg_mae = running_mae / num_batches\n",
    "        avg_accuracy = running_accuracy / num_batches\n",
    "        avg_f1 = running_f1 / num_batches\n",
    "        vicreg_losses.append(avg_vicreg_loss)\n",
    "        mse_losses.append(avg_mse)\n",
    "        rmse_losses.append(avg_rmse)\n",
    "        mae_losses.append(avg_mae)\n",
    "        accuracy_scores.append(avg_accuracy)\n",
    "        f1_scores.append(avg_f1)\n",
    "        \n",
    "        print(f\"✅ Epoch {epoch:3d}/{num_epochs} (mu={mu}) - VICReg Loss: {avg_vicreg_loss:.4f}, \"\n",
    "              f\"MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, \"\n",
    "              f\"Accuracy: {avg_accuracy:.8f}, F1-Score: {avg_f1:.8f}\")\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'projector_state_dict': projector.state_dict(),\n",
    "            'linear_reg_state_dict': linear_reg.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'vicreg_mu_{mu}_epoch_{epoch}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logging.info(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        final_model_path = os.path.join(checkpoint_dir, f'vicreg_model_final_mu_{mu}.pth')\n",
    "        final_projector_path = os.path.join(checkpoint_dir, f'vicreg_projector_final_mu_{mu}.pth')\n",
    "        final_linear_reg_path = os.path.join(checkpoint_dir, f'vicreg_linear_reg_final_mu_{mu}.pth')\n",
    "        final_classifier_path = os.path.join(checkpoint_dir, f'vicreg_classifier_final_mu_{mu}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        torch.save(projector.state_dict(), final_projector_path)\n",
    "        torch.save(linear_reg.state_dict(), final_linear_reg_path)\n",
    "        torch.save(classifier.state_dict(), final_classifier_path)\n",
    "        logging.info(f\"Saved final models (mu={mu}): {final_model_path}, {final_projector_path}, {final_linear_reg_path}, {final_classifier_path}\")\n",
    "        # Append metrics to DataFrame\n",
    "        metrics_df.append({\n",
    "            'mu': mu,\n",
    "            'epoch': epoch,\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        })\n",
    "\n",
    "# Initialize an empty list to collect metrics\n",
    "all_metrics = []\n",
    "#for mu_val in [20.0, 23.0, 25.0, 27.0, 30.0, 33.0]:\n",
    "for mu_val in [27.0]:\n",
    "    train_vicreg_with_mu(mu=mu_val, num_epochs=60, metrics_df=all_metrics)\n",
    "\n",
    "# Convert metrics to DataFrame and save to CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv(os.path.join(checkpoint_dir, 'vicreg_metrics.csv'), index=False)\n",
    "logging.info(f\"Saved metrics to {os.path.join(checkpoint_dir, 'import torch')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a98c5c-254c-4bf3-9959-4ae2df88a6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
