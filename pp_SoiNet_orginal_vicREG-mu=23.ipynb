{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed2af90-41fe-421f-9437-c88c92c6a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6074e36-5ec1-418c-a3ed-7418a23fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Kiểm tra và đặt thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd6067-3711-4638-95c3-5a4091e0e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df):\n",
    "    new_df = df.copy()\n",
    "    deleted_count = 0\n",
    "    valid_indices = []\n",
    "    for idx, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "        path = row[\"path\"]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            valid_indices.append(idx)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    new_df = new_df.loc[valid_indices].reset_index(drop=True)\n",
    "    logging.info(f\"Deleted {deleted_count} labeled images. {len(new_df)} images remain.\")\n",
    "    return new_df\n",
    "\n",
    "def preprocess_unlabeled_images(image_paths):\n",
    "    new_image_paths = []\n",
    "    deleted_count = 0\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img.verify()\n",
    "            new_image_paths.append(path)\n",
    "        except (UnidentifiedImageError, FileNotFoundError, OSError) as e:\n",
    "            logging.info(f\"Image error: {path} ({str(e)})\")\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    deleted_count += 1\n",
    "                    logging.info(f\"Deleted image: {path}\")\n",
    "            except (PermissionError, OSError) as e:\n",
    "                logging.error(f\"Cannot delete image {path}: {str(e)}\")\n",
    "    logging.info(f\"Deleted {deleted_count} unlabeled images. {len(new_image_paths)} images remain.\")\n",
    "    return new_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190a3635-2aaa-4852-8846-996eb51d127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2057/2057 [01:05<00:00, 31.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2052/2052 [01:05<00:00, 31.32it/s]\n"
     ]
    }
   ],
   "source": [
    "label_csv_path = r\"F:\\Soil_Labeled_Data\\labels.csv\"\n",
    "fallback_dir = r\"F:\\Soil_Labeled_Data\\augmented_fallback\"\n",
    "os.makedirs(fallback_dir, exist_ok=True)\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df = preprocess_images(df)\n",
    "\n",
    "augment = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "replaced_count = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    path = row[\"path\"]\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img.verify()\n",
    "    except (UnidentifiedImageError, FileNotFoundError, OSError):\n",
    "        folder = os.path.dirname(path)\n",
    "        all_images = [f for f in os.listdir(folder) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "        good_images = [f for f in all_images if f != os.path.basename(path)]\n",
    "        if not good_images:\n",
    "            continue\n",
    "        candidate = random.choice(good_images)\n",
    "        candidate_path = os.path.join(folder, candidate)\n",
    "        try:\n",
    "            img = Image.open(candidate_path).convert(\"RGB\")\n",
    "            img_aug = augment(img)\n",
    "            new_filename = f\"aug_{os.path.basename(path)}\"\n",
    "            new_path = os.path.join(fallback_dir, new_filename)\n",
    "            img_aug.save(new_path)\n",
    "            df.at[idx, \"path\"] = new_path\n",
    "            replaced_count += 1\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba635eb-f1dc-4fbd-a0d8-0227a00e0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11995/11995 [01:24<00:00, 141.99it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dir = r\"F:/unlabeled_images\"\n",
    "image_paths = []\n",
    "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"]:\n",
    "    image_paths.extend(glob.glob(os.path.join(image_dir, \"**\", ext), recursive=True))\n",
    "image_paths = preprocess_unlabeled_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96588c62-959b-4472-be0f-fbcc5eb1f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "labeled_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img1 = self.transform(image)\n",
    "            img2 = self.transform(image)\n",
    "            return img1, img2\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_paths))\n",
    "\n",
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(image)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading image {img_path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        humidity = torch.tensor([row['SM_0'] / 100, row['SM_20'] / 100], dtype=torch.float32)\n",
    "        class_label = torch.tensor(row[\"moisture_class\"], dtype=torch.long)\n",
    "        return img, humidity, class_label\n",
    "\n",
    "unlabeled_dataset = UnlabeledImageDataset(image_paths, transform)\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "labeled_dataset = LabeledImageDataset(df, labeled_transform)\n",
    "labeled_dataloader = DataLoader(labeled_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "class SoilNetDualHead(nn.Module):\n",
    "    def __init__(self, num_classes=10, simclr_mode=False):\n",
    "        super().__init__()\n",
    "        self.simclr_mode = simclr_mode\n",
    "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.mnv2_block1 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[0:3]\n",
    "        )\n",
    "        self.channel_adapter = nn.Conv2d(32, 16, kernel_size=1, bias=False)\n",
    "        self.mobilevit_full = timm.create_model(\"mobilevitv2_050\", pretrained=True)\n",
    "        self.mobilevit_encoder = self.mobilevit_full.stages\n",
    "        self.mvit_to_mnv2 = nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "        self.mnv2_block2 = nn.Sequential(*list(\n",
    "            timm.create_model(\"mobilenetv2_100.ra_in1k\", pretrained=True).blocks.children())[3:7]\n",
    "        )\n",
    "        self.final_conv = nn.Conv2d(320, 1280, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.light_dense = nn.Sequential(nn.Linear(1, 32), nn.ReLU(inplace=True))\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(1280 + 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_light=None):\n",
    "        x = self.initial_conv(x_img)\n",
    "        x = self.mnv2_block1(x)\n",
    "        x = self.channel_adapter(x)\n",
    "        x = self.mobilevit_encoder(x)\n",
    "        x = self.mvit_to_mnv2(x)\n",
    "        x = self.mnv2_block2(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.pool(x)\n",
    "        x_img_feat = torch.flatten(x, 1)\n",
    "        if self.simclr_mode:\n",
    "            return x_img_feat\n",
    "        x_light_feat = self.light_dense(x_light)\n",
    "        x_concat = torch.cat([x_img_feat, x_light_feat], dim=1)\n",
    "        reg_out = self.reg_head(x_concat)\n",
    "        cls_out = self.cls_head(x_concat)\n",
    "        return reg_out, cls_out\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, input_dim=1280, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_dim, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class OnlineLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class OnlineClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def vicreg_loss(z1, z2, lambda_=25.0, mu=25.0, nu=1.0, epsilon=1e-4):\n",
    "    invariance_loss = F.mse_loss(z1, z2)\n",
    "    def variance_term(z):\n",
    "        z_std = torch.sqrt(z.var(dim=0) + epsilon)\n",
    "        return torch.mean(F.relu(1 - z_std))\n",
    "    var_loss = variance_term(z1) + variance_term(z2)\n",
    "    def covariance_term(z):\n",
    "        z = z - z.mean(dim=0)\n",
    "        cov = (z.T @ z) / (z.shape[0] - 1)\n",
    "        off_diag = cov - torch.diag(cov.diag())\n",
    "        return off_diag.pow(2).sum() / z.shape[1]\n",
    "    cov_loss = covariance_term(z1) + covariance_term(z2)\n",
    "    return lambda_ * invariance_loss + mu * var_loss + nu * cov_loss\n",
    "\n",
    "model = SoilNetDualHead(num_classes=10, simclr_mode=True).to(device)\n",
    "projector = Projector(input_dim=1280, proj_dim=128).to(device)\n",
    "linear_reg = OnlineLinearRegression(input_dim=1280, output_dim=2).to(device)\n",
    "classifier = OnlineClassifier(input_dim=1280, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89271f6e-e617-4fb5-84bf-ee8d8d7132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(r\"C:\\Users\\PC\\soilNet\\Model\\SoilNet_orginal.pth\", map_location=device))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "optimizer_vicreg = torch.optim.Adam(list(model.parameters()) + list(projector.parameters()), lr=1e-4)\n",
    "optimizer_linear = torch.optim.Adam(linear_reg.parameters(), lr=1e-3)\n",
    "optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "\n",
    "#checkpoint_dir = \"/content/drive/MyDrive/SoilNet_Checkpoints/checkpoints_VicReg\"\n",
    "checkpoint_dir = r\"C:\\Users\\PC\\soilNet\\checkpoints_VicReg\"\n",
    "\n",
    "#C:\\Users\\PC\\soilNet\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e040f89a-3f5e-47ed-ad72-c2edf6eff441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   1/60 (mu=23.0) - VICReg Loss: 33.6809, MSE: 1704.9341, RMSE: 41.2908, MAE: 31.7326, Accuracy: 0.17673565, F1-Score: 0.17615663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   2/60 (mu=23.0) - VICReg Loss: 32.0441, MSE: 1115.6623, RMSE: 33.4015, MAE: 26.6929, Accuracy: 0.17665220, F1-Score: 0.17839606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   3/60 (mu=23.0) - VICReg Loss: 30.8096, MSE: 1045.5670, RMSE: 32.3352, MAE: 26.1234, Accuracy: 0.17598465, F1-Score: 0.17779897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   4/60 (mu=23.0) - VICReg Loss: 29.7278, MSE: 1010.3742, RMSE: 31.7864, MAE: 25.6210, Accuracy: 0.18583111, F1-Score: 0.18805564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   5/60 (mu=23.0) - VICReg Loss: 28.7959, MSE: 954.3522, RMSE: 30.8926, MAE: 24.8595, Accuracy: 0.19442590, F1-Score: 0.19799921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   6/60 (mu=23.0) - VICReg Loss: 27.7342, MSE: 883.6075, RMSE: 29.7255, MAE: 23.8444, Accuracy: 0.19776368, F1-Score: 0.19999952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   7/60 (mu=23.0) - VICReg Loss: 26.8971, MSE: 877.4409, RMSE: 29.6216, MAE: 23.7629, Accuracy: 0.21295060, F1-Score: 0.21520595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   8/60 (mu=23.0) - VICReg Loss: 25.9186, MSE: 872.7252, RMSE: 29.5419, MAE: 23.4976, Accuracy: 0.22329773, F1-Score: 0.22792275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch   9/60 (mu=23.0) - VICReg Loss: 24.9105, MSE: 798.2411, RMSE: 28.2532, MAE: 22.5123, Accuracy: 0.23306075, F1-Score: 0.23835293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  10/60 (mu=23.0) - VICReg Loss: 24.1605, MSE: 794.9024, RMSE: 28.1940, MAE: 22.6281, Accuracy: 0.22847130, F1-Score: 0.23202537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  11/60 (mu=23.0) - VICReg Loss: 23.3213, MSE: 797.9258, RMSE: 28.2476, MAE: 22.5036, Accuracy: 0.23439586, F1-Score: 0.23605327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  12/60 (mu=23.0) - VICReg Loss: 22.6707, MSE: 760.6228, RMSE: 27.5794, MAE: 22.0053, Accuracy: 0.24908211, F1-Score: 0.25244830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  13/60 (mu=23.0) - VICReg Loss: 21.9166, MSE: 787.2607, RMSE: 28.0582, MAE: 22.5031, Accuracy: 0.24182243, F1-Score: 0.24562611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  14/60 (mu=23.0) - VICReg Loss: 21.2478, MSE: 788.3518, RMSE: 28.0776, MAE: 22.4161, Accuracy: 0.24290721, F1-Score: 0.24580255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  15/60 (mu=23.0) - VICReg Loss: 20.6052, MSE: 784.8339, RMSE: 28.0149, MAE: 22.3847, Accuracy: 0.24332443, F1-Score: 0.24570260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  16/60 (mu=23.0) - VICReg Loss: 20.2909, MSE: 780.4515, RMSE: 27.9366, MAE: 22.3431, Accuracy: 0.23806742, F1-Score: 0.24276664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  17/60 (mu=23.0) - VICReg Loss: 19.7632, MSE: 773.8696, RMSE: 27.8185, MAE: 22.2895, Accuracy: 0.23723298, F1-Score: 0.24033738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  18/60 (mu=23.0) - VICReg Loss: 19.4967, MSE: 786.4632, RMSE: 28.0440, MAE: 22.4466, Accuracy: 0.24749666, F1-Score: 0.25121476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  19/60 (mu=23.0) - VICReg Loss: 19.1419, MSE: 796.7360, RMSE: 28.2265, MAE: 22.6618, Accuracy: 0.24449266, F1-Score: 0.24819587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  20/60 (mu=23.0) - VICReg Loss: 18.8331, MSE: 797.4813, RMSE: 28.2397, MAE: 22.6450, Accuracy: 0.23840120, F1-Score: 0.24132646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  21/60 (mu=23.0) - VICReg Loss: 18.6168, MSE: 806.5379, RMSE: 28.3996, MAE: 22.8268, Accuracy: 0.24073765, F1-Score: 0.24314590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  22/60 (mu=23.0) - VICReg Loss: 18.3859, MSE: 822.6846, RMSE: 28.6825, MAE: 22.8965, Accuracy: 0.24090454, F1-Score: 0.24651671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  23/60 (mu=23.0) - VICReg Loss: 18.3022, MSE: 793.4413, RMSE: 28.1681, MAE: 22.5407, Accuracy: 0.24140521, F1-Score: 0.24706884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  24/60 (mu=23.0) - VICReg Loss: 18.2052, MSE: 833.4708, RMSE: 28.8699, MAE: 23.1878, Accuracy: 0.24082109, F1-Score: 0.24605052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  25/60 (mu=23.0) - VICReg Loss: 18.0210, MSE: 822.4273, RMSE: 28.6780, MAE: 23.0275, Accuracy: 0.24941589, F1-Score: 0.25265586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  26/60 (mu=23.0) - VICReg Loss: 17.8879, MSE: 837.0573, RMSE: 28.9319, MAE: 23.3076, Accuracy: 0.24499332, F1-Score: 0.24782150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  27/60 (mu=23.0) - VICReg Loss: 17.7718, MSE: 810.9156, RMSE: 28.4766, MAE: 22.8626, Accuracy: 0.24532710, F1-Score: 0.24749070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  28/60 (mu=23.0) - VICReg Loss: 17.5967, MSE: 849.7724, RMSE: 29.1509, MAE: 23.3366, Accuracy: 0.24057076, F1-Score: 0.24469260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  29/60 (mu=23.0) - VICReg Loss: 17.5439, MSE: 841.5183, RMSE: 29.0089, MAE: 23.2139, Accuracy: 0.23698264, F1-Score: 0.23876293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  30/60 (mu=23.0) - VICReg Loss: 17.5688, MSE: 828.4661, RMSE: 28.7831, MAE: 23.0884, Accuracy: 0.23623164, F1-Score: 0.23974830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  31/60 (mu=23.0) - VICReg Loss: 17.4625, MSE: 861.2808, RMSE: 29.3476, MAE: 23.6551, Accuracy: 0.23548064, F1-Score: 0.23936895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  32/60 (mu=23.0) - VICReg Loss: 17.3312, MSE: 829.0248, RMSE: 28.7928, MAE: 23.0690, Accuracy: 0.24299065, F1-Score: 0.24477135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  33/60 (mu=23.0) - VICReg Loss: 17.2668, MSE: 837.7093, RMSE: 28.9432, MAE: 23.2061, Accuracy: 0.23865154, F1-Score: 0.24299357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  34/60 (mu=23.0) - VICReg Loss: 17.2297, MSE: 865.3320, RMSE: 29.4165, MAE: 23.6064, Accuracy: 0.24248999, F1-Score: 0.24554750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  35/60 (mu=23.0) - VICReg Loss: 17.1559, MSE: 834.5510, RMSE: 28.8886, MAE: 23.1586, Accuracy: 0.24023698, F1-Score: 0.24371048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  36/60 (mu=23.0) - VICReg Loss: 17.1162, MSE: 841.5531, RMSE: 29.0095, MAE: 23.3302, Accuracy: 0.23431242, F1-Score: 0.23850457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  37/60 (mu=23.0) - VICReg Loss: 17.1070, MSE: 851.5086, RMSE: 29.1806, MAE: 23.4260, Accuracy: 0.23723298, F1-Score: 0.23835797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  38/60 (mu=23.0) - VICReg Loss: 17.0820, MSE: 827.8075, RMSE: 28.7716, MAE: 23.1618, Accuracy: 0.23581442, F1-Score: 0.23858114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  39/60 (mu=23.0) - VICReg Loss: 17.0932, MSE: 882.6460, RMSE: 29.7094, MAE: 23.8864, Accuracy: 0.22588451, F1-Score: 0.22903618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  40/60 (mu=23.0) - VICReg Loss: 17.0521, MSE: 867.3713, RMSE: 29.4512, MAE: 23.6643, Accuracy: 0.23931909, F1-Score: 0.24088891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  41/60 (mu=23.0) - VICReg Loss: 16.9305, MSE: 874.4572, RMSE: 29.5712, MAE: 23.8318, Accuracy: 0.23506342, F1-Score: 0.23857445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  42/60 (mu=23.0) - VICReg Loss: 16.9036, MSE: 890.9007, RMSE: 29.8480, MAE: 23.9544, Accuracy: 0.23981976, F1-Score: 0.24142573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  43/60 (mu=23.0) - VICReg Loss: 16.8701, MSE: 855.3673, RMSE: 29.2467, MAE: 23.5089, Accuracy: 0.23706609, F1-Score: 0.23792503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  44/60 (mu=23.0) - VICReg Loss: 16.8625, MSE: 883.7112, RMSE: 29.7273, MAE: 23.9415, Accuracy: 0.23481308, F1-Score: 0.23395731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  45/60 (mu=23.0) - VICReg Loss: 16.8369, MSE: 885.8426, RMSE: 29.7631, MAE: 24.0749, Accuracy: 0.24307410, F1-Score: 0.24401170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  46/60 (mu=23.0) - VICReg Loss: 16.8508, MSE: 870.5941, RMSE: 29.5058, MAE: 23.7549, Accuracy: 0.24023698, F1-Score: 0.24112659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  47/60 (mu=23.0) - VICReg Loss: 16.7444, MSE: 895.0300, RMSE: 29.9171, MAE: 23.9739, Accuracy: 0.23556409, F1-Score: 0.23709794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  48/60 (mu=23.0) - VICReg Loss: 16.7515, MSE: 878.9145, RMSE: 29.6465, MAE: 23.9172, Accuracy: 0.23973632, F1-Score: 0.24213204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  49/60 (mu=23.0) - VICReg Loss: 16.6878, MSE: 885.1434, RMSE: 29.7514, MAE: 23.9580, Accuracy: 0.23456275, F1-Score: 0.23748674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  50/60 (mu=23.0) - VICReg Loss: 16.6245, MSE: 903.0635, RMSE: 30.0510, MAE: 24.1548, Accuracy: 0.23364486, F1-Score: 0.23550481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  51/60 (mu=23.0) - VICReg Loss: 16.6935, MSE: 918.6780, RMSE: 30.3097, MAE: 24.4158, Accuracy: 0.22997330, F1-Score: 0.23227485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  52/60 (mu=23.0) - VICReg Loss: 16.6420, MSE: 923.5534, RMSE: 30.3900, MAE: 24.4762, Accuracy: 0.22822096, F1-Score: 0.23021900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  53/60 (mu=23.0) - VICReg Loss: 16.6335, MSE: 918.7861, RMSE: 30.3115, MAE: 24.5457, Accuracy: 0.23022363, F1-Score: 0.23048774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  54/60 (mu=23.0) - VICReg Loss: 16.5852, MSE: 936.9823, RMSE: 30.6102, MAE: 24.6437, Accuracy: 0.22621829, F1-Score: 0.22617279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  55/60 (mu=23.0) - VICReg Loss: 16.5758, MSE: 899.7804, RMSE: 29.9963, MAE: 24.2279, Accuracy: 0.23247664, F1-Score: 0.23463621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  56/60 (mu=23.0) - VICReg Loss: 16.6546, MSE: 887.2359, RMSE: 29.7865, MAE: 24.0754, Accuracy: 0.23114152, F1-Score: 0.23365658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  57/60 (mu=23.0) - VICReg Loss: 16.4933, MSE: 900.4289, RMSE: 30.0071, MAE: 24.2418, Accuracy: 0.23256008, F1-Score: 0.23350216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  58/60 (mu=23.0) - VICReg Loss: 16.5452, MSE: 937.4924, RMSE: 30.6185, MAE: 24.8164, Accuracy: 0.22938919, F1-Score: 0.23062076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  59/60 (mu=23.0) - VICReg Loss: 16.5665, MSE: 959.4323, RMSE: 30.9747, MAE: 25.0085, Accuracy: 0.22530040, F1-Score: 0.22564305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch  60/60 (mu=23.0) - VICReg Loss: 16.5201, MSE: 954.5723, RMSE: 30.8962, MAE: 24.9363, Accuracy: 0.22680240, F1-Score: 0.22855938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def train_vicreg_with_mu(mu=25.0, num_epochs=150, metrics_df=None):\n",
    "    vicreg_losses, mse_losses, rmse_losses, mae_losses, accuracy_scores, f1_scores = [], [], [], [], [], []\n",
    "    labeled_iterator = iter(labeled_dataloader)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        projector.train()\n",
    "        linear_reg.train()\n",
    "        classifier.train()\n",
    "        running_vicreg_loss = running_mse = running_mae = running_accuracy = running_f1 = 0.0\n",
    "        num_batches = 0\n",
    "        for img1, img2 in tqdm(unlabeled_dataloader, leave=False):\n",
    "            img1, img2 = img1.to(device), img2.to(device)\n",
    "            feat1 = model(img1, x_light=None)\n",
    "            feat2 = model(img2, x_light=None)\n",
    "            z1 = projector(feat1)\n",
    "            z2 = projector(feat2)\n",
    "            vicreg_loss_val = vicreg_loss(z1, z2, mu=mu)\n",
    "            optimizer_vicreg.zero_grad()\n",
    "            vicreg_loss_val.backward()\n",
    "            optimizer_vicreg.step()\n",
    "            try:\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            except StopIteration:\n",
    "                labeled_iterator = iter(labeled_dataloader)\n",
    "                labeled_img, humidity, class_label = next(labeled_iterator)\n",
    "            labeled_img, humidity, class_label = labeled_img.to(device), humidity.to(device), class_label.to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = model(labeled_img, x_light=None)\n",
    "            pred_humidity = linear_reg(feat)\n",
    "            mse_loss = F.mse_loss(pred_humidity, humidity)\n",
    "            optimizer_linear.zero_grad()\n",
    "            mse_loss.backward()\n",
    "            optimizer_linear.step()\n",
    "            pred_logits = classifier(feat)\n",
    "            cls_loss = F.cross_entropy(pred_logits, class_label)\n",
    "            optimizer_classifier.zero_grad()\n",
    "            cls_loss.backward()\n",
    "            optimizer_classifier.step()\n",
    "            pred_humidity_np = pred_humidity.detach().cpu().numpy() * 100\n",
    "            humidity_np = humidity.detach().cpu().numpy() * 100\n",
    "            mse = mean_squared_error(humidity_np, pred_humidity_np)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(humidity_np, pred_humidity_np)\n",
    "            pred_classes = torch.argmax(pred_logits, dim=1).detach().cpu().numpy()\n",
    "            true_classes = class_label.detach().cpu().numpy()\n",
    "            accuracy = accuracy_score(true_classes, pred_classes)\n",
    "            f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
    "            running_vicreg_loss += vicreg_loss_val.item()\n",
    "            running_mse += mse\n",
    "            running_mae += mae\n",
    "            running_accuracy += accuracy\n",
    "            running_f1 += f1\n",
    "            num_batches += 1\n",
    "        avg_vicreg_loss = running_vicreg_loss / num_batches\n",
    "        avg_mse = running_mse / num_batches\n",
    "        avg_rmse = np.sqrt(avg_mse)\n",
    "        avg_mae = running_mae / num_batches\n",
    "        avg_accuracy = running_accuracy / num_batches\n",
    "        avg_f1 = running_f1 / num_batches\n",
    "        vicreg_losses.append(avg_vicreg_loss)\n",
    "        mse_losses.append(avg_mse)\n",
    "        rmse_losses.append(avg_rmse)\n",
    "        mae_losses.append(avg_mae)\n",
    "        accuracy_scores.append(avg_accuracy)\n",
    "        f1_scores.append(avg_f1)\n",
    "        \n",
    "        print(f\"✅ Epoch {epoch:3d}/{num_epochs} (mu={mu}) - VICReg Loss: {avg_vicreg_loss:.4f}, \"\n",
    "              f\"MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, \"\n",
    "              f\"Accuracy: {avg_accuracy:.8f}, F1-Score: {avg_f1:.8f}\")\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'projector_state_dict': projector.state_dict(),\n",
    "            'linear_reg_state_dict': linear_reg.state_dict(),\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'vicreg_mu_{mu}_epoch_{epoch}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logging.info(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        final_model_path = os.path.join(checkpoint_dir, f'vicreg_model_final_mu_{mu}.pth')\n",
    "        final_projector_path = os.path.join(checkpoint_dir, f'vicreg_projector_final_mu_{mu}.pth')\n",
    "        final_linear_reg_path = os.path.join(checkpoint_dir, f'vicreg_linear_reg_final_mu_{mu}.pth')\n",
    "        final_classifier_path = os.path.join(checkpoint_dir, f'vicreg_classifier_final_mu_{mu}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        torch.save(projector.state_dict(), final_projector_path)\n",
    "        torch.save(linear_reg.state_dict(), final_linear_reg_path)\n",
    "        torch.save(classifier.state_dict(), final_classifier_path)\n",
    "        logging.info(f\"Saved final models (mu={mu}): {final_model_path}, {final_projector_path}, {final_linear_reg_path}, {final_classifier_path}\")\n",
    "        # Append metrics to DataFrame\n",
    "        metrics_df.append({\n",
    "            'mu': mu,\n",
    "            'epoch': epoch,\n",
    "            'vicreg_loss': avg_vicreg_loss,\n",
    "            'mse_loss': avg_mse,\n",
    "            'rmse_loss': avg_rmse,\n",
    "            'mae_loss': avg_mae,\n",
    "            'accuracy': avg_accuracy,\n",
    "            'f1_score': avg_f1\n",
    "        })\n",
    "\n",
    "# Initialize an empty list to collect metrics\n",
    "all_metrics = []\n",
    "#for mu_val in [20.0, 23.0, 25.0, 27.0, 30.0, 33.0]:\n",
    "for mu_val in [23.0]:\n",
    "    train_vicreg_with_mu(mu=mu_val, num_epochs=60, metrics_df=all_metrics)\n",
    "\n",
    "# Convert metrics to DataFrame and save to CSV\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv(os.path.join(checkpoint_dir, 'vicreg_metrics.csv'), index=False)\n",
    "logging.info(f\"Saved metrics to {os.path.join(checkpoint_dir, 'import torch')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
